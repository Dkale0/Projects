{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fba9c3",
   "metadata": {},
   "source": [
    "## Categorizing MNIST dataset using CNN (Convolutional Neural Networks) - Darsh Kale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f0421",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30238a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] The specified module could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbfa98",
   "metadata": {},
   "source": [
    "### Enable Cuda (GPU computation)\n",
    "\n",
    "With the folllowing line we can set device to be run on the GPU instead of the CPU. For datasets that are huge a GPU may provivde much faster model training speeds compared to CPU's. This is because GPU's allow for heavy parallelization due to the large amount of cores they have high data throughput in camparison to the smaller amount (but faster) that CPU's have. However in our case, the MNIST datset is small enough and our model complexity is not that high, so the GPU's benefits of parallelization/high data throughput are overpowered by the CPU file I/O speeds. Note that this only works if your have Cuda version installed on your device that is compatible with the pytorch version you are using. Additionaly you must also ensure that your GPU is compatible with the Cuda toolkit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7aa5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNCOMMENT LINE BELOW FOR GPU\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3698c",
   "metadata": {},
   "source": [
    "### Download/Extract Data\n",
    "\n",
    "Since the MNIST dataset is already size-normalized and centered we could download the data from [website](http://yann.lecun.com/exdb/mnist/) into a folder, and extract it using libraries such as gzip (look [here](https://stackoverflow.com/questions/40427435/extract-images-from-idx3-ubyte-file-or-gzip-via-python) for detailed explanations). However, out of convenience we simply use [this](https://stackoverflow.com/questions/64080130/how-to-import-the-mnist-dataset-from-local-directory-using-pytorch/64081743#64081743) solution that downloads and extracts data from the torchvision library. Note that we also transform each image into a tensor, which will be useful later into this project as we will build a CNN using the torch library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37980159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not adviced to add the following line, however we want to format our outputs. Thus we get rid of warnings as such:\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = 'samples',\n",
    "    # ToTensor() normalizes images between 0.0 and 1.0\n",
    "    transform = torchvision.transforms.ToTensor(), \n",
    "    train = True,    \n",
    "    download = True,            \n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = 'samples', \n",
    "    train = False, \n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c99f89",
   "metadata": {},
   "source": [
    "We can check to see if we correctly retrieved the data, by plotting one of the images and its respective label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c3cd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[1000])\n",
    "plt.title(train_data.targets[1000])\n",
    "plt.show()\n",
    "\n",
    "train_data.data[1].size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255d311",
   "metadata": {},
   "source": [
    "### Set up DataLoaders\n",
    "\n",
    "DataLoaders simplify preprocessing our data, before we use it for training our model. They can split our dataset into batches and shuffle the data (increases generalization). It is a Map-style dataset, which means it provides random-access capabilities, which allow for easier parallel loading (useful for large datasets like ours).\n",
    "\n",
    "The reasoning behind the parameters we set for DataLoader function:\n",
    "* batch_size: A smaller batch size would have more parameter updates per epoch and would be more noisy as loss is calculated over a smaller subset (less overfitting). We chose 128 as our batch size, which is on the smaller side.\n",
    "* shuffle: When shuffle is True, it helps to not have data look alike bwtween epochs. By default shuffle=True uses RandomSampler, while false uses SequentialSampler.\n",
    "* num_workers: General rule of thumb, num_workers = num_GPU * 4; when num_workser=0 it does data loading when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842fd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb2dcb",
   "metadata": {},
   "source": [
    "### Building our Model\n",
    "\n",
    "CNN is a class of neural newtork that is most commonly used to process images. It consists of two main steps. The first step extracts the most important features. It does so using the 3 layers: Covolutional lauer, ReLU correction lauer, and the Pooling layer (in the same order). In our model below we apply these 3 layers 3 times for this first part of our model. For the 2nd part of our model we take the output from the previous part apply linear combinations and the softmax activation function, which gives an output vector of size 10 (since we have 10 classes). \n",
    "\n",
    "#### Part 1\n",
    "\n",
    "Layer 1,2 parameters:\n",
    "The first convulutional layer has the following parameters:\n",
    "* in_channels: We set this to 1 since we have a greyscale image (values range from 0 to 255)\n",
    "* out_channel: This is the number of channels (feature maps), we use 32.\n",
    "* kernel_size: We chose a 3x3 kernel size. Generally odd kernel sizes are preferred over even since they symmetrically divide the previous layer pixels around the output pixel\n",
    "* stride: A higher stride equates to less data needs to be processed, more generalization. We chose stride of 1 as our image is small(28x28) more information preserved.\n",
    "* padding: We choose padding=0 as the information at the edges of the images is unnecessary since the numbers are centered\n",
    "\n",
    "ReLU function has no parameters\n",
    "\n",
    "Layers 3-6 parameters:\n",
    "The convulutional functions have their in_channel set to the out_channel of the previous convulution layer. Their ou_channel is half of their current in_channel. Stride, kernel_size, and padding remain the same. ReLU once again, takes in no parameter.\n",
    "\n",
    "Layer 7 parameters:\n",
    "Initially we had maxpooling layers after each convulutional + ReLU layer, however this resulted in too much data loss, and increased model training time. We removed 2 of these max pooling layers, only keeping the last max pooling layer, which marks the end of part 1. \n",
    "\n",
    "Max Pooling function:\n",
    "* kernel_size: We set this to 2 as we want to minimize information loss since our images are already small and lower quality.\n",
    "\n",
    "#### Part 2\n",
    "\n",
    "Layer 8 parameters:\n",
    "Flatten takes in no parameters. This function takes each batch of images and flattens each image seperately (reduces the matrix into vector form).\n",
    "\n",
    "Layers 9-11 parameters:\n",
    "the torch.nn.linear function applies a linear transformation, y=x*w^T + b where x is the incoming data, \n",
    "y is the output, W are the weights (initially random) and b are the biases that are both updated during the training of our model. In the end, our goal is to transform the output from layer 8 into a vector of length 10, which will be the probabilities for each class 0-9.\n",
    "\n",
    "Linear transformation function: \n",
    "For layer 9:\n",
    "* in_channels: this is the size (# of features) for input. Since the output from layer 8 has the dimensions 128 x 968, our input for in_channels will be 968. This will allow a valid form of matrix multiplication where x is (128 x 968) and W will be (968 x out_channels).\n",
    "* out_channels: We set this 512. Note we are ultimately trying to reduce this to 10. We choose some number x that is smaller than the in_channels and where x = 2^n for some n to make the computation efficient. \n",
    "* bias: this is set to true by default and will be included in our model. \n",
    "For layer 10, 11:\n",
    "The in_channel will be the out_channel of the previous layer. The final out_channel (layer 11) wil be 10 since there will be a probability for each of our 10 classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6c1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "                                                ### 1st Part\n",
    "    # layers 1,2\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "    torch.nn.ReLU(),\n",
    "    #torch.nn.MaxPool2d(kernel_size=2),\n",
    "    \n",
    "    # layers 3,4\n",
    "    torch.nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "    torch.nn.ReLU(),\n",
    "    #torch.nn.MaxPool2d(kernel_size=2),\n",
    "   \n",
    "    # layers 5,6\n",
    "    torch.nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=0),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    # layer 7\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "                                                ### 2nd Part\n",
    "    \n",
    "    # layer 8\n",
    "    torch.nn.Flatten(),\n",
    "    \n",
    "    # layer 9,10,11\n",
    "    torch.nn.Linear(in_features=968, out_features=512),\n",
    "    torch.nn.Linear(in_features=512, out_features=128),\n",
    "    torch.nn.Linear(in_features=128, out_features=10)   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050bc5c",
   "metadata": {},
   "source": [
    "### Loss and Optimization Function\n",
    "\n",
    "#### Loss Function\n",
    "For our loss function we use the Multiclass Cross Entropy Loss function as it is suitable for our image classification problem This function gives a measure of how close the true distribution of probabilities for the classes (numbers 0-9) is to our predicted distribution. Our goal during fitting our model is to minimize the loss calculated by this function.\n",
    "\n",
    "#### Optimization Function\n",
    "Our optimizatoin function is Adam (Adaptive Moment Estimation) type. It is an extension to the stochastic gradient decent algorithm, and has large adoption in deeplearning applications in computer vision due to its simplicity and effectiveness. [This](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) link gives a more detailed explanation of this function. THe learning rate (a.k.a. alpha or step size) is the proportion the weights (W in the torch.nn.Linear method) is updated by. Larger learning rates may reach a conclusion in less updates however them may also lead to divergence if set too high, on the other hand small learning rates would take many more updates to arrive at a global minima (for loss) or may find a local minima instead of a global one. Finding the right learning rate is a complex process, and [this](https://www.jeremyjordan.me/nn-learning-rate/) article provide a detailed guide on how one might find the best learning rate for your model. We choose a learning rate of 1e-4 (After a non-sytematic approach of randomly trying different lr's and comparing their accuracy). The default parameters (that we use) are beta1=0.9, beta2=0.999, epsilon=1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69beb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7425645",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "To train our model we first decide how many epochs to train it over. Training it for too many epochs may result in overfitting, while too little would result in lower accuracy (higher loss). We first choose a fairly large number ~20 epochs and check at what epoch our loss stops decreasing and starts increasing (avg of 2-3 epochs) or the decrease in loss is unsubstantial. We determine that 7 epochs seems to be optimal in our case. Next for each batch of data from the train_dataloader we first set our optimizers weights to zero with zero_grad(). Next we get the predicted probabilites (transformed by torch.nn.linear) for each class for that batch of data. We then calculate loss based on this output and the true label for the training data set. Next, loss.backward() is the back propgation step that finds the updates for our parameters and optimizer.step() actually updates the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93eb186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.0057, grad_fn=<NllLossBackward0>)\n",
      "1 tensor(0.0155, grad_fn=<NllLossBackward0>)\n",
      "2 tensor(0.0171, grad_fn=<NllLossBackward0>)\n",
      "3 tensor(0.0140, grad_fn=<NllLossBackward0>)\n",
      "4 tensor(0.0425, grad_fn=<NllLossBackward0>)\n",
      "5 tensor(0.0138, grad_fn=<NllLossBackward0>)\n",
      "6 tensor(0.0062, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## UNCOMMENT LINE BELOW FOR GPU\n",
    "#model.to(device)\n",
    "for epoch in range(7):\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        ## UNCOMMENT LINE BELOW FOR GPU\n",
    "        # images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)   \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d93ce1",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "\n",
    "We finally test our model on the training dataset. The torch.no_grad() function disables gradient calculations over the weights (note: this will NOT affect the accuracy of the model) reducing memory consumption. Next we get all the batches of data from the test_loader, and get the prdicted probabilities (note, these are after applying the linear transformation so range is not 0 to 1, but magnitude/order is the same) for each class. Then using the torch.max() function we get the maximum value from the tensors (returns both value and index). We increment total number of imagess (this will be 10,000 at the end) and also increment the number of images correctly classified for that particular batch of images. Finally we calculate the test accuracy by dividing the total correctly classified images by total images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bcfb1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9872\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0], data[1]\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted[1] == labels).sum().item()\n",
    "print(\"Test accuracy: \", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7dbde",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Our test accuracy is over 97% consistently. Running this notebook again may not produce the same results since dataloader randomly choses images for batches which will affect the training of our final model. Overall, convolutional neural networks seem to be ideal for training models to categorize images quickly and accurately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
