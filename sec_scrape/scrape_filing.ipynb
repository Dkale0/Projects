{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import requests, json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys ## all keyboard keys imported\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os, time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import copy\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrape_Filing(webdriver.Chrome):\n",
    "    def __init__(self, driver_path=None, teardown=False):\n",
    "        if driver_path == None:\n",
    "            driver_path = os.path.abspath(os.getcwd()) ## Gets current working directory\n",
    "        self.driver_path = driver_path\n",
    "        self.teardown = teardown\n",
    "        os.environ['PATH'] += self.driver_path\n",
    "        options = webdriver.ChromeOptions()\n",
    "        #options.add_experimental_option('excludeSwitches', ['enable-logging']) ## stops the warnings related to reading file descriptors logs\n",
    "        \n",
    "        download_path = driver_path + '\\\\path_files'   # set path for when we download the filing to minimize requests sent to server when we parse it \n",
    "        self.download_path = download_path\n",
    "        preferences = {\n",
    "            \"download.default_directory\":download_path\n",
    "            \n",
    "        }\n",
    "        options.add_experimental_option(\"prefs\", preferences)\n",
    "       \n",
    "        super(Scrape_Filing, self).__init__(options=options) ## use super to instantiate the webdriver.chrome class\n",
    "        self.implicitly_wait(15)\n",
    "        # self.maximize_window()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb): ## method to close the chrome window\n",
    "        if self.teardown:\n",
    "            self.quit()\n",
    "            \n",
    "    def find_file(self, name, path):\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            if name in files:\n",
    "                return os.path.join(root, name)\n",
    " \n",
    "        \n",
    "    def find_cik(self, company=\"BlackRock Inc.\"):\n",
    "        self.get(\"https://www.sec.gov/edgar/searchedgar/cik.htm\")\n",
    "        company_element = self.find_element_by_id(\"company\")\n",
    "        company_element.send_keys(company)\n",
    "        submit_element = self.find_element_by_class_name(\"search-button\")\n",
    "        submit_element.click() \n",
    "       \n",
    "        try:\n",
    "\n",
    "            table_element = self.find_element_by_css_selector(\"table[summary='Results of CIK Lookup']\")\n",
    "            rows = table_element.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "            td_row = rows[0].find_elements(By.TAG_NAME, \"td\") ## d_row has 2 rows\n",
    "            \n",
    "            pre_list = td_row[1].find_elements(By.TAG_NAME, \"pre\") ## there are 2 <pre> tags in 2nd rows\n",
    "            cik = pre_list[1].find_elements(By.TAG_NAME, \"a\")[0].text ## we access the very first <pre> tag and the first a tags text is our cik \n",
    "            return cik\n",
    "        except Exception as e:\n",
    "            print(\"try a different name\")\n",
    "            \n",
    "    def find_filing_address(self, cik, year=2020, quarter=1, only_10k=False): ## by default finds 10k, otherwise choose from quarter=1-4\n",
    "        new_filename = f\"master_{year}_{quarter}.txt\"\n",
    "        if self.find_file(new_filename, self.download_path): ## To prevent re downloading files, and make the program more efficient\n",
    "            \n",
    "            print(\"Found File\")\n",
    "        else:\n",
    "        \n",
    "            master_idx_url = f\"https://www.sec.gov/Archives/edgar/full-index/{str(year)}/QTR{str(quarter)}/\"\n",
    "            self.get(master_idx_url)\n",
    "            table_element = self.find_element_by_css_selector(\"table[summary='heding']\")\n",
    "            rows_element = table_element.find_elements(By.TAG_NAME, \"tr\")\n",
    "            master_idx_link = rows_element[11].find_element(By.TAG_NAME, \"a\")\n",
    "            master_idx_link.click()\n",
    "            time.sleep(2) ## sleep to let file download\n",
    "\n",
    "\n",
    "            filename = max([self.download_path + \"\\\\\" + f for f in os.listdir(self.download_path)],key=os.path.getctime)\n",
    "            print(filename)\n",
    "\n",
    "            shutil.move(filename,os.path.join(self.download_path,new_filename))\n",
    "            \n",
    "        \n",
    "        stripped_cik = cik.lstrip(\"0\") ## strip the preceding zeroes in the string cik\n",
    "        add_10q = []\n",
    "        add_10k = []\n",
    "        with open(self.download_path + \"\\\\\" + new_filename) as fp:\n",
    "            for line in fp:\n",
    "                if stripped_cik in line:\n",
    "                    if \"10-Q\" in line:\n",
    "                        add_10q.append(line) \n",
    "                    if \"10-K\" in line:\n",
    "                        add_10k.append(line)\n",
    "                        \n",
    "        if add_10k == [] and add_10q == []:\n",
    "            print(\"No filings found\")\n",
    "            return None\n",
    "                        \n",
    "        return_address = []\n",
    "        \n",
    "        if only_10k == True:\n",
    "            if add_10k == []:\n",
    "                return None\n",
    "            else:\n",
    "                for line in add_10k:\n",
    "                    return_address.append(line.split('|')[4])\n",
    "                complete_address = \"https://www.sec.gov/Archives/\" + return_address[0].strip(\"\\n\")\n",
    "                return complete_address ## for now only returns complete address of first filing we find that is either a 10-K or 10-Q\n",
    "            \n",
    "                        \n",
    "        ## Single quarter archive has multiple 10-Q, or both 10-K and 10-Q reports for some company(ie. some international companies)\n",
    "        for line in add_10q:\n",
    "            return_address.append(line.split('|')[4])\n",
    "            \n",
    "        complete_address = \"https://www.sec.gov/Archives/\" + return_address[0].strip(\"\\n\")\n",
    "        return complete_address ## for now only returns complete address of first filing we find that is either a 10-K or 10-Q\n",
    "            \n",
    "        \n",
    "      \n",
    "    def find_10k_address(self, cik, year): ## Since companies may release their 10k's in different quarters\n",
    "        for i in range(1, 5):\n",
    "            address_10k = self.find_filing_address(cik=cik, year=year, quarter=i, only_10k=True)\n",
    "            if address_10k != None:\n",
    "                return address_10k\n",
    "        return None\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseFiling():\n",
    "    def __init__(self):\n",
    "        self.filing = dict()\n",
    "        self.filing['sec_header_content'] = {}\n",
    "        self.filing['filing_documents'] = None\n",
    "        self.test = 0\n",
    "        \n",
    "    def retrieve_filing(self, file_address):\n",
    "        response = requests.get(file_address)\n",
    "        filing = BeautifulSoup(response.content, 'lxml')\n",
    "        sec_header_tag = filing.find('sec-header')\n",
    "        \n",
    "\n",
    "        \n",
    "        display(sec_header_tag)\n",
    "        \n",
    "        # find condendsed consolidated statements of financial condition\n",
    "        #<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\" style=\"margin:auto;border-collapse:collapse; width:100%;\">\n",
    "        print(\"huhhhshh\")\n",
    "        i = 0\n",
    "#         for filing_document in filing.find('document'):\n",
    "#             document_filename = filing_document.filename.find(text=True, recursive=False).strip()\n",
    "#             #print(i, \": \", document_filename)\n",
    "#             display(document_filename) \n",
    "#             i+=1\n",
    "#             #master_document_dict[document_id]['document_filename'] = document_filename\n",
    "            \n",
    "        \n",
    "                \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found File\n"
     ]
    }
   ],
   "source": [
    "BlackRock10k = Scrape_Filing()\n",
    "#cik = BlackRock10k.find_cik(\"BlackRock Inc.\")\n",
    "cik = '0001364742'\n",
    "file_address = BlackRock10k.find_filing_address(cik, year=2019, quarter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huhhhshh\n"
     ]
    }
   ],
   "source": [
    "Parse_BR = ParseFiling()\n",
    "Parse_BR.retrieve_filing(file_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001364742'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000789019\n",
      "Found File\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-61b59c92985c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mms_cik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMicrosoftCorp10k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_cik\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Microsoft Corp\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# use abbreviations such as Corp, Ltd, Inc, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mms_cik\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mMicrosoftCorp10k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_filing_address\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mms_cik\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2019\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mMicrosoftCorp10k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_filing_address\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mms_cik\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2019\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-105e395fa63c>\u001b[0m in \u001b[0;36mfind_filing_address\u001b[1;34m(self, cik, year, quarter, only_10k)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mreturn_address\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mcomplete_address\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.sec.gov/Archives/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mreturn_address\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplete_address\u001b[0m \u001b[1;31m## for now only returns complete address of first filing we find that is either a 10-K or 10-Q\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "MicrosoftCorp10k = Scrape_Filing()\n",
    "ms_cik = MicrosoftCorp10k.find_cik(\"Microsoft Corp\") # use abbreviations such as Corp, Ltd, Inc, etc.\n",
    "print(ms_cik)\n",
    "MicrosoftCorp10k.find_filing_address(ms_cik, 2019, 3)\n",
    "MicrosoftCorp10k.find_filing_address(ms_cik, 2019, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found File\n",
      "Found File\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/1239188/0001144204-19-017485.txt'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general steel holdings\n",
    "warnings.filterwarnings('ignore')\n",
    "GS_10k = Scrape_Filing()\n",
    "gs_cik = GS_10k.find_cik(\"GENERAL STEEL HOLDINGS INC\")\n",
    "# GS_10k.find_filing_address(gs_cik, 2019, 1)\n",
    "# GS_10k.find_filing_address(gs_cik, 2019, 2)\n",
    "# GS_10k.find_filing_address(gs_cik, 2019, 3)\n",
    "# GS_10k.find_filing_address(gs_cik, 2019, 4)\n",
    "GS_10k.find_10k_address(gs_cik, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000789019\n",
      "Found File\n",
      "Found File\n",
      "Found File\n",
      "https://www.sec.gov/Archives/edgar/data/789019/0001564590-19-027952.txt\n"
     ]
    }
   ],
   "source": [
    "MicrosoftCorp10k = Scrape_Filing()\n",
    "ms_cik = MicrosoftCorp10k.find_cik(\"Microsoft Corp\")\n",
    "print(ms_cik)\n",
    "add_10k = MicrosoftCorp10k.find_10k_address(ms_cik, 2019)\n",
    "print(add_10k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\darsh\\\\personal-repo\\\\projects\\\\sec_scrape'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
